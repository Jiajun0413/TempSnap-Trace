{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.getcwd()\n",
    "os.chdir('/home/liujiajun/projects/Hap_networks/module/04-15')\n",
    "from TempSnap import IOManager\n",
    "mcan_tables = IOManager.load_from_hdf5('/home/liujiajun/projects/Hap_networks/module/Brazil/results_0422/McAN_raw_results_2020-09-01_to_2021-03-02.h5')\n",
    "graphs = IOManager.load_from_hdf5('/home/liujiajun/projects/Hap_networks/module/Brazil/results_0422/Temporal_graphs_2020-09-01_to_2021-03-02.h5')\n",
    "communities= IOManager.load_from_hdf5('/home/liujiajun/projects/Hap_networks/module/Brazil/results_0422/Community_structures_2020-09-01_to_2021-03-02.h5')\n",
    "backbone_tables = IOManager.load_from_hdf5('/home/liujiajun/projects/Hap_networks/module/Brazil/results_0422/Backbone_tables_2020-09-01_to_2021-03-02.h5')\n",
    "backbone_networks = IOManager.load_from_hdf5('/home/liujiajun/projects/Hap_networks/module/Brazil/results_0422/Backbone_networks_2020-09-01_to_2021-03-02.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.getcwd()\n",
    "os.chdir('/home/liujiajun/projects/Hap_networks/module/04-15')\n",
    "from TempSnap import IOManager\n",
    "mcan_tables2 = IOManager.load_from_hdf5('/home/liujiajun/projects/Hap_networks/module/Brazil/results_0422_2/McAN_raw_results_2020-06-01_to_2020-11-30.h5')\n",
    "graphs2 = IOManager.load_from_hdf5('/home/liujiajun/projects/Hap_networks/module/Brazil/results_0422_2/Temporal_graphs_2020-06-01_to_2020-11-30.h5')\n",
    "communities2= IOManager.load_from_hdf5('/home/liujiajun/projects/Hap_networks/module/Brazil/results_0422_2/Community_structures_2020-06-01_to_2020-11-30.h5')\n",
    "backbone_tables2 = IOManager.load_from_hdf5('/home/liujiajun/projects/Hap_networks/module/Brazil/results_0422_2/Backbone_tables_2020-06-01_to_2020-11-30.h5')\n",
    "backbone_networks2 = IOManager.load_from_hdf5('/home/liujiajun/projects/Hap_networks/module/Brazil/results_0422_2/Backbone_networks_2020-06-01_to_2020-11-30.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'Trace' in sys.modules:\n",
    "    del sys.modules['Trace']\n",
    "from Trace import track_community_evolution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(graphs2)):\n",
    "    if graphs2[i]:\n",
    "        print(f\"max date is {max(graphs2[i].vs['Date'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcan_tables2[25]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing graphs from index 0 to 22, corresponding to approx. date range: 2020-06-08 to 2020-11-02\n",
      "Using GPU similarity calculator.\n",
      "Starting tracking from 53 target communities...\n",
      "Identified 98 communities in the evolution chain (53 targets + 45 tracked predecessors). Tracking took 4.36s.\n",
      "Generated tracking DataFrame with 98 rows.\n",
      "Identified 7 root nodes and 53 labeled nodes. Total 56 unique start points for chain building.\n",
      "Building chains in parallel using 4 processes...\n",
      "Constructed 56 raw chains containing the label.\n",
      "Reduced to 10 unique chains after deduplication. Chain construction took 0.44s.\n",
      "Tracking results successfully saved to ./tracking_results_label_P.2_20200601_20201102.h5.\n",
      "Total processing time: 6.66s\n"
     ]
    }
   ],
   "source": [
    "tracking_chains_eu= track_community_evolution(\n",
    "    partitions=communities2,\n",
    "    extended_graphs=graphs2,\n",
    "    label_of_interest='P.2',\n",
    "    tracking_label='Lineage',\n",
    "    recording_label='Lineage',\n",
    "    start_date='2020-06-01',\n",
    "    end_date='2020-11-02',\n",
    "    time_interval=7,\n",
    "    similarity_threshold=0.5,\n",
    "    weight_attr=\"wdks\",\n",
    "    n_processes=4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_chains_eu= IOManager.load_from_hdf5('/home/liujiajun/projects/Hap_networks/module/04-15/tracking_results_label_P.2_20200601_20201102.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Community ID</th>\n",
       "      <th>Contains Label</th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Lineage Counts</th>\n",
       "      <th>Matched From Date</th>\n",
       "      <th>Matched From Community ID</th>\n",
       "      <th>Core Node</th>\n",
       "      <th>Mutations_of_core_node</th>\n",
       "      <th>Matched From Time Index</th>\n",
       "      <th>Alternative Matched From</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-06-29</th>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>{\"B.1.1.28\": 2}</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>B.1.1.28</td>\n",
       "      <td>1(Deletion:-AT-TAAAGG-----&gt;-);14(SNP:T-&gt;A);15(...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-06</th>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>0.898</td>\n",
       "      <td>{\"B.1.1.28\": 5}</td>\n",
       "      <td>2020-06-29</td>\n",
       "      <td>8</td>\n",
       "      <td>B.1.1.28</td>\n",
       "      <td>1(Deletion:-AT-TAAAGG-----&gt;-);14(SNP:T-&gt;A);15(...</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-13</th>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000</td>\n",
       "      <td>{\"B.1.1.28\": 5}</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>6</td>\n",
       "      <td>B.1.1.28</td>\n",
       "      <td>1(Deletion:-AT-TAAAGG-----&gt;-);14(SNP:T-&gt;A);15(...</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-20</th>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000</td>\n",
       "      <td>{\"B.1.1.28\": 5}</td>\n",
       "      <td>2020-07-13</td>\n",
       "      <td>6</td>\n",
       "      <td>B.1.1.28</td>\n",
       "      <td>1(Deletion:-AT-TAAAGG-----&gt;-);14(SNP:T-&gt;A);15(...</td>\n",
       "      <td>6</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-27</th>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000</td>\n",
       "      <td>{\"B.1.1.28\": 5}</td>\n",
       "      <td>2020-07-20</td>\n",
       "      <td>10</td>\n",
       "      <td>B.1.1.28</td>\n",
       "      <td>1(Deletion:-AT-TAAAGG-----&gt;-);14(SNP:T-&gt;A);15(...</td>\n",
       "      <td>7</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-03</th>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000</td>\n",
       "      <td>{\"B.1.1.28\": 5}</td>\n",
       "      <td>2020-07-27</td>\n",
       "      <td>12</td>\n",
       "      <td>B.1.1.28</td>\n",
       "      <td>1(Deletion:-AT-TAAAGG-----&gt;-);14(SNP:T-&gt;A);15(...</td>\n",
       "      <td>8</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-10</th>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000</td>\n",
       "      <td>{\"B.1.1.28\": 5}</td>\n",
       "      <td>2020-08-03</td>\n",
       "      <td>14</td>\n",
       "      <td>B.1.1.28</td>\n",
       "      <td>1(Deletion:-AT-TAAAGG-----&gt;-);14(SNP:T-&gt;A);15(...</td>\n",
       "      <td>9</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-17</th>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000</td>\n",
       "      <td>{\"B.1.1.28\": 5}</td>\n",
       "      <td>2020-08-10</td>\n",
       "      <td>16</td>\n",
       "      <td>B.1.1.28</td>\n",
       "      <td>1(Deletion:-AT-TAAAGG-----&gt;-);14(SNP:T-&gt;A);15(...</td>\n",
       "      <td>10</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-24</th>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000</td>\n",
       "      <td>{\"B.1.1.28\": 5}</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>17</td>\n",
       "      <td>B.1.1.28</td>\n",
       "      <td>1(Deletion:-AT-TAAAGG-----&gt;-);14(SNP:T-&gt;A);15(...</td>\n",
       "      <td>11</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-31</th>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000</td>\n",
       "      <td>{\"B.1.1.28\": 5}</td>\n",
       "      <td>2020-08-24</td>\n",
       "      <td>19</td>\n",
       "      <td>B.1.1.28</td>\n",
       "      <td>1(Deletion:-AT-TAAAGG-----&gt;-);14(SNP:T-&gt;A);15(...</td>\n",
       "      <td>12</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-07</th>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000</td>\n",
       "      <td>{\"B.1.1.28\": 5}</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>19</td>\n",
       "      <td>B.1.1.28</td>\n",
       "      <td>1(Deletion:-AT-TAAAGG-----&gt;-);14(SNP:T-&gt;A);15(...</td>\n",
       "      <td>13</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-14</th>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000</td>\n",
       "      <td>{\"B.1.1.28\": 5}</td>\n",
       "      <td>2020-09-07</td>\n",
       "      <td>22</td>\n",
       "      <td>B.1.1.28</td>\n",
       "      <td>1(Deletion:-AT-TAAAGG-----&gt;-);14(SNP:T-&gt;A);15(...</td>\n",
       "      <td>14</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-21</th>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000</td>\n",
       "      <td>{\"B.1.1.28\": 5}</td>\n",
       "      <td>2020-09-14</td>\n",
       "      <td>24</td>\n",
       "      <td>B.1.1.28</td>\n",
       "      <td>1(Deletion:-AT-TAAAGG-----&gt;-);14(SNP:T-&gt;A);15(...</td>\n",
       "      <td>15</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-28</th>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000</td>\n",
       "      <td>{\"B.1.1.28\": 5}</td>\n",
       "      <td>2020-09-21</td>\n",
       "      <td>25</td>\n",
       "      <td>B.1.1.28</td>\n",
       "      <td>1(Deletion:-AT-TAAAGG-----&gt;-);14(SNP:T-&gt;A);15(...</td>\n",
       "      <td>16</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-05</th>\n",
       "      <td>33</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000</td>\n",
       "      <td>{\"B.1.1.28\": 5}</td>\n",
       "      <td>2020-09-28</td>\n",
       "      <td>30</td>\n",
       "      <td>B.1.1.28</td>\n",
       "      <td>1(Deletion:-AT-TAAAGG-----&gt;-);14(SNP:T-&gt;A);15(...</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-12</th>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000</td>\n",
       "      <td>{\"B.1.1.28\": 5}</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>33</td>\n",
       "      <td>B.1.1.28</td>\n",
       "      <td>1(Deletion:-AT-TAAAGG-----&gt;-);14(SNP:T-&gt;A);15(...</td>\n",
       "      <td>18</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-19</th>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>0.957</td>\n",
       "      <td>{\"B.1.1.28\": 5, \"P.2\": 1}</td>\n",
       "      <td>2020-10-12</td>\n",
       "      <td>36</td>\n",
       "      <td>B.1.1.28</td>\n",
       "      <td>1(Deletion:-AT-TAAAGG-----&gt;-);14(SNP:T-&gt;A);15(...</td>\n",
       "      <td>19</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-26</th>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>{\"B.1.1.28\": 5, \"P.2\": 1}</td>\n",
       "      <td>2020-10-19</td>\n",
       "      <td>6</td>\n",
       "      <td>B.1.1.28</td>\n",
       "      <td>1(Deletion:-AT-TAAAGG-----&gt;-);14(SNP:T-&gt;A);15(...</td>\n",
       "      <td>20</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-02</th>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000</td>\n",
       "      <td>{\"B.1.1.28\": 5, \"P.2\": 1}</td>\n",
       "      <td>2020-10-26</td>\n",
       "      <td>6</td>\n",
       "      <td>B.1.1.28</td>\n",
       "      <td>1(Deletion:-AT-TAAAGG-----&gt;-);14(SNP:T-&gt;A);15(...</td>\n",
       "      <td>21</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Community ID  Contains Label Similarity  \\\n",
       "Date                                                  \n",
       "2020-06-29             8           False      0.000   \n",
       "2020-07-06             6           False      0.898   \n",
       "2020-07-13             6           False      1.000   \n",
       "2020-07-20            10           False      1.000   \n",
       "2020-07-27            12           False      1.000   \n",
       "2020-08-03            14           False      1.000   \n",
       "2020-08-10            16           False      1.000   \n",
       "2020-08-17            17           False      1.000   \n",
       "2020-08-24            19           False      1.000   \n",
       "2020-08-31            19           False      1.000   \n",
       "2020-09-07            22           False      1.000   \n",
       "2020-09-14            24           False      1.000   \n",
       "2020-09-21            25           False      1.000   \n",
       "2020-09-28            30           False      1.000   \n",
       "2020-10-05            33           False      1.000   \n",
       "2020-10-12            36           False      1.000   \n",
       "2020-10-19             6            True      0.957   \n",
       "2020-10-26             6            True      1.000   \n",
       "2020-11-02             7            True      1.000   \n",
       "\n",
       "                       Lineage Counts Matched From Date  \\\n",
       "Date                                                      \n",
       "2020-06-29            {\"B.1.1.28\": 2}              <NA>   \n",
       "2020-07-06            {\"B.1.1.28\": 5}        2020-06-29   \n",
       "2020-07-13            {\"B.1.1.28\": 5}        2020-07-06   \n",
       "2020-07-20            {\"B.1.1.28\": 5}        2020-07-13   \n",
       "2020-07-27            {\"B.1.1.28\": 5}        2020-07-20   \n",
       "2020-08-03            {\"B.1.1.28\": 5}        2020-07-27   \n",
       "2020-08-10            {\"B.1.1.28\": 5}        2020-08-03   \n",
       "2020-08-17            {\"B.1.1.28\": 5}        2020-08-10   \n",
       "2020-08-24            {\"B.1.1.28\": 5}        2020-08-17   \n",
       "2020-08-31            {\"B.1.1.28\": 5}        2020-08-24   \n",
       "2020-09-07            {\"B.1.1.28\": 5}        2020-08-31   \n",
       "2020-09-14            {\"B.1.1.28\": 5}        2020-09-07   \n",
       "2020-09-21            {\"B.1.1.28\": 5}        2020-09-14   \n",
       "2020-09-28            {\"B.1.1.28\": 5}        2020-09-21   \n",
       "2020-10-05            {\"B.1.1.28\": 5}        2020-09-28   \n",
       "2020-10-12            {\"B.1.1.28\": 5}        2020-10-05   \n",
       "2020-10-19  {\"B.1.1.28\": 5, \"P.2\": 1}        2020-10-12   \n",
       "2020-10-26  {\"B.1.1.28\": 5, \"P.2\": 1}        2020-10-19   \n",
       "2020-11-02  {\"B.1.1.28\": 5, \"P.2\": 1}        2020-10-26   \n",
       "\n",
       "           Matched From Community ID Core Node  \\\n",
       "Date                                             \n",
       "2020-06-29                      <NA>  B.1.1.28   \n",
       "2020-07-06                         8  B.1.1.28   \n",
       "2020-07-13                         6  B.1.1.28   \n",
       "2020-07-20                         6  B.1.1.28   \n",
       "2020-07-27                        10  B.1.1.28   \n",
       "2020-08-03                        12  B.1.1.28   \n",
       "2020-08-10                        14  B.1.1.28   \n",
       "2020-08-17                        16  B.1.1.28   \n",
       "2020-08-24                        17  B.1.1.28   \n",
       "2020-08-31                        19  B.1.1.28   \n",
       "2020-09-07                        19  B.1.1.28   \n",
       "2020-09-14                        22  B.1.1.28   \n",
       "2020-09-21                        24  B.1.1.28   \n",
       "2020-09-28                        25  B.1.1.28   \n",
       "2020-10-05                        30  B.1.1.28   \n",
       "2020-10-12                        33  B.1.1.28   \n",
       "2020-10-19                        36  B.1.1.28   \n",
       "2020-10-26                         6  B.1.1.28   \n",
       "2020-11-02                         6  B.1.1.28   \n",
       "\n",
       "                                       Mutations_of_core_node  \\\n",
       "Date                                                            \n",
       "2020-06-29  1(Deletion:-AT-TAAAGG----->-);14(SNP:T->A);15(...   \n",
       "2020-07-06  1(Deletion:-AT-TAAAGG----->-);14(SNP:T->A);15(...   \n",
       "2020-07-13  1(Deletion:-AT-TAAAGG----->-);14(SNP:T->A);15(...   \n",
       "2020-07-20  1(Deletion:-AT-TAAAGG----->-);14(SNP:T->A);15(...   \n",
       "2020-07-27  1(Deletion:-AT-TAAAGG----->-);14(SNP:T->A);15(...   \n",
       "2020-08-03  1(Deletion:-AT-TAAAGG----->-);14(SNP:T->A);15(...   \n",
       "2020-08-10  1(Deletion:-AT-TAAAGG----->-);14(SNP:T->A);15(...   \n",
       "2020-08-17  1(Deletion:-AT-TAAAGG----->-);14(SNP:T->A);15(...   \n",
       "2020-08-24  1(Deletion:-AT-TAAAGG----->-);14(SNP:T->A);15(...   \n",
       "2020-08-31  1(Deletion:-AT-TAAAGG----->-);14(SNP:T->A);15(...   \n",
       "2020-09-07  1(Deletion:-AT-TAAAGG----->-);14(SNP:T->A);15(...   \n",
       "2020-09-14  1(Deletion:-AT-TAAAGG----->-);14(SNP:T->A);15(...   \n",
       "2020-09-21  1(Deletion:-AT-TAAAGG----->-);14(SNP:T->A);15(...   \n",
       "2020-09-28  1(Deletion:-AT-TAAAGG----->-);14(SNP:T->A);15(...   \n",
       "2020-10-05  1(Deletion:-AT-TAAAGG----->-);14(SNP:T->A);15(...   \n",
       "2020-10-12  1(Deletion:-AT-TAAAGG----->-);14(SNP:T->A);15(...   \n",
       "2020-10-19  1(Deletion:-AT-TAAAGG----->-);14(SNP:T->A);15(...   \n",
       "2020-10-26  1(Deletion:-AT-TAAAGG----->-);14(SNP:T->A);15(...   \n",
       "2020-11-02  1(Deletion:-AT-TAAAGG----->-);14(SNP:T->A);15(...   \n",
       "\n",
       "           Matched From Time Index Alternative Matched From  \n",
       "Date                                                         \n",
       "2020-06-29                    <NA>                       []  \n",
       "2020-07-06                       4                       []  \n",
       "2020-07-13                       5                       []  \n",
       "2020-07-20                       6                       []  \n",
       "2020-07-27                       7                       []  \n",
       "2020-08-03                       8                       []  \n",
       "2020-08-10                       9                       []  \n",
       "2020-08-17                      10                       []  \n",
       "2020-08-24                      11                       []  \n",
       "2020-08-31                      12                       []  \n",
       "2020-09-07                      13                       []  \n",
       "2020-09-14                      14                       []  \n",
       "2020-09-21                      15                       []  \n",
       "2020-09-28                      16                       []  \n",
       "2020-10-05                      17                       []  \n",
       "2020-10-12                      18                       []  \n",
       "2020-10-19                      19                       []  \n",
       "2020-10-26                      20                       []  \n",
       "2020-11-02                      21                       []  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_chains_eu[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=tracking_chains_eu[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2=tracking_chains_eu[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t3=tracking_chains_eu[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t4=tracking_chains_eu[4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5=tracking_chains_eu[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Trace import extract_community_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 199 nodes in 0.0039s\n"
     ]
    }
   ],
   "source": [
    "nodes_df1 = extract_community_nodes(\n",
    "    community_id=0,\n",
    "    date_str='2020-11-02',\n",
    "    graphs=graphs2,\n",
    "    communities=communities2,\n",
    "    chains=tracking_chains_eu, # 传入 final_chains\n",
    "    debug=True\n",
    ")#0611RS_E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 15 nodes in 0.0079s\n"
     ]
    }
   ],
   "source": [
    "nodes_df2 = extract_community_nodes(\n",
    "    community_id=2,\n",
    "    date_str='2020-11-02',\n",
    "    graphs=graphs2,\n",
    "    communities=communities2,\n",
    "    chains=tracking_chains_eu, # 传入 final_chains\n",
    "    debug=True\n",
    ")#1019flo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 26 nodes in 0.0031s\n"
     ]
    }
   ],
   "source": [
    "nodes_df3 = extract_community_nodes(\n",
    "    community_id=17,\n",
    "    date_str='2020-09-14',\n",
    "    graphs=graphs2,\n",
    "    communities=communities2,\n",
    "    chains=tracking_chains_eu, # 传入 final_chains\n",
    "    debug=True\n",
    ")#0706SP_RP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 29 nodes in 0.0032s\n"
     ]
    }
   ],
   "source": [
    "nodes_df4 = extract_community_nodes(\n",
    "    community_id=3,\n",
    "    date_str='2020-11-02',\n",
    "    graphs=graphs2,\n",
    "    communities=communities2,\n",
    "    chains=tracking_chains_eu, # 传入 final_chains\n",
    "    debug=True\n",
    ")#pra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 34 nodes in 2.6455s\n"
     ]
    }
   ],
   "source": [
    "nodes_df5 = extract_community_nodes(\n",
    "    community_id=13,\n",
    "    date_str='2020-09-28',\n",
    "    graphs=graphs2,\n",
    "    communities=communities2,\n",
    "    chains=tracking_chains_eu, # 传入 final_chains\n",
    "    debug=True\n",
    ")#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional, Set, Tuple\n",
    "import numpy as np\n",
    "import colorsys\n",
    "import igraph as ig\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "import json\n",
    "\n",
    "def extract_date_range_optimized(graphs, start_date, end_date, time_interval):\n",
    "    \"\"\"优化的日期范围提取函数\"\"\"\n",
    "    user_specified_start = start_date is not None\n",
    "    user_specified_end = end_date is not None\n",
    "    \n",
    "    # 提取每个图的最大日期 (缓存优化)\n",
    "    graph_dates = []\n",
    "    \n",
    "    for idx, g in enumerate(graphs):\n",
    "        if not g or not g.vs or 'Date' not in g.vs.attributes():\n",
    "            graph_dates.append((idx, None))\n",
    "            continue\n",
    "        \n",
    "        # 一次性收集所有有效日期\n",
    "        valid_dates = []\n",
    "        for v in g.vs:\n",
    "            if 'Date' in v.attributes() and v['Date']:\n",
    "                try:\n",
    "                    valid_dates.append(pd.Timestamp(v['Date']))\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        # 找出最大日期\n",
    "        if valid_dates:\n",
    "            graph_dates.append((idx, max(valid_dates)))\n",
    "        else:\n",
    "            graph_dates.append((idx, None))\n",
    "    \n",
    "    # 过滤掉无效日期\n",
    "    valid_graph_dates = [(idx, date) for idx, date in graph_dates if date is not None]\n",
    "    if not valid_graph_dates:\n",
    "        return -1, -1, None\n",
    "        \n",
    "    # 转换用户指定的日期\n",
    "    try:\n",
    "        start_timestamp = pd.Timestamp(start_date) if user_specified_start else None\n",
    "        end_timestamp = pd.Timestamp(end_date) if user_specified_end else None\n",
    "    except:\n",
    "        return -1, -1, None\n",
    "    \n",
    "    # 确定开始索引\n",
    "    start_idx = 0\n",
    "    if user_specified_start and valid_graph_dates:\n",
    "        candidates = [(idx, date) for idx, date in valid_graph_dates if date <= start_timestamp]\n",
    "        if candidates:\n",
    "            start_idx = max(candidates, key=lambda x: x[1])[0]\n",
    "    \n",
    "    # 确定结束索引\n",
    "    end_idx = len(graphs) - 1\n",
    "    if user_specified_end and valid_graph_dates:\n",
    "        candidates = [(idx, date) for idx, date in valid_graph_dates if date >= end_timestamp]\n",
    "        if candidates:\n",
    "            end_idx = min(candidates, key=lambda x: x[1])[0]\n",
    "        else:\n",
    "            end_idx = valid_graph_dates[-1][0]\n",
    "    \n",
    "    if start_idx > end_idx:\n",
    "        return -1, -1, None\n",
    "    \n",
    "    # 获取选定范围的实际日期\n",
    "    actual_max_dates = []\n",
    "    for idx in range(start_idx, end_idx + 1):\n",
    "        if idx < len(graph_dates) and graph_dates[idx][1] is not None:\n",
    "            actual_max_dates.append(graph_dates[idx][1])\n",
    "        else:\n",
    "            if actual_max_dates:\n",
    "                last_date = actual_max_dates[-1]\n",
    "                actual_max_dates.append(last_date + pd.Timedelta(days=time_interval))\n",
    "            else:\n",
    "                base_date = pd.Timestamp(start_date) if start_date else pd.Timestamp.now()\n",
    "                actual_max_dates.append(base_date)\n",
    "    \n",
    "    return start_idx, end_idx, actual_max_dates\n",
    "\n",
    "def create_graph_optimized(node_data, community_data, chains):\n",
    "    \"\"\"优化的图结构创建函数\"\"\"\n",
    "    G = ig.Graph(directed=True)\n",
    "    G.add_vertices(list(node_data.keys()))\n",
    "    \n",
    "    # 设置节点属性 (批量设置)\n",
    "    for v in G.vs:\n",
    "        node_id = v['name']\n",
    "        if node_id in node_data:\n",
    "            attrs = node_data[node_id]\n",
    "            for key, value in attrs.items():\n",
    "                v[key] = value\n",
    "    \n",
    "    # 预处理边 (内部边+核心边)\n",
    "    all_edges = []\n",
    "    \n",
    "    # 按社区分组预处理节点\n",
    "    nodes_by_community = defaultdict(list)\n",
    "    for node_id, attrs in node_data.items():\n",
    "        key = (attrs['date'], attrs['community_id'])\n",
    "        nodes_by_community[key].append(node_id)\n",
    "    \n",
    "    # 添加社区内部边\n",
    "    intra_edges = []\n",
    "    for community_nodes in nodes_by_community.values():\n",
    "        if len(community_nodes) <= 1:\n",
    "            continue\n",
    "            \n",
    "        # 使用直接组合生成内部边\n",
    "        for i in range(len(community_nodes)):\n",
    "            for j in range(i+1, len(community_nodes)):\n",
    "                intra_edges.append((community_nodes[i], community_nodes[j], {'type': 'intra'}))\n",
    "    \n",
    "    # 添加核心节点演化边\n",
    "    core_edges = []\n",
    "    core_nodes = {}\n",
    "    # 安全地获取核心节点\n",
    "    for node_id, attrs in node_data.items():\n",
    "        if 'is_core' in attrs and attrs['is_core']:\n",
    "            key = (attrs['date'], attrs['community_id'])\n",
    "            core_nodes[key] = node_id\n",
    "    \n",
    "    # 分析链条\n",
    "    for chain_df in [df for df in chains if not df.empty]:\n",
    "        for i in range(len(chain_df) - 1):\n",
    "            # 获取日期和社区ID\n",
    "            if 'Date' in chain_df.columns:\n",
    "                src_date = str(chain_df.iloc[i]['Date'])\n",
    "                tgt_date = str(chain_df.iloc[i+1]['Date'])\n",
    "            else:\n",
    "                src_date = str(chain_df.index[i])\n",
    "                tgt_date = str(chain_df.index[i+1])\n",
    "                \n",
    "            src_comm = int(chain_df.iloc[i]['Community ID'])\n",
    "            tgt_comm = int(chain_df.iloc[i+1]['Community ID'])\n",
    "            \n",
    "            # 查找核心节点\n",
    "            src_core = core_nodes.get((src_date, src_comm))\n",
    "            tgt_core = core_nodes.get((tgt_date, tgt_comm))\n",
    "            \n",
    "            if src_core and tgt_core:\n",
    "                # 获取边属性\n",
    "                similarity = float(chain_df.iloc[i+1]['Similarity']) if 'Similarity' in chain_df.columns else 0.5\n",
    "                evo_weight = float(chain_df.iloc[i+1]['evo_weights']) if 'evo_weights' in chain_df.columns else 0.5\n",
    "                \n",
    "                edge_attrs = {\n",
    "                    'type': 'core', \n",
    "                    'weight': similarity,\n",
    "                    'evo_weight': evo_weight\n",
    "                }\n",
    "                core_edges.append((src_core, tgt_core, edge_attrs))\n",
    "    \n",
    "    # 合并边并添加到图中\n",
    "    all_edges = intra_edges + core_edges\n",
    "    if all_edges:\n",
    "        G.add_edges([(e[0], e[1]) for e in all_edges])\n",
    "        for i, (source, target, attrs) in enumerate(all_edges):\n",
    "            for key, value in attrs.items():\n",
    "                G.es[i][key] = value\n",
    "                \n",
    "    return G\n",
    "\n",
    "def filter_nodes_by_clade(nodes, expected_clades, debug=False, date_str=None, community_id=None):\n",
    "    \"\"\"根据预期的Clade过滤节点 (保留原函数)\"\"\"\n",
    "    if not expected_clades:\n",
    "        return nodes\n",
    "        \n",
    "    filtered_nodes = []\n",
    "    found_clades = Counter(n['clade'] for n in nodes if n['clade'])\n",
    "    \n",
    "    # 检查缺失的Clade\n",
    "    missing_clades = [clade for clade in expected_clades.keys() if clade not in found_clades]\n",
    "    if missing_clades and debug:\n",
    "        print(f\"警告: 缺失Clade: {missing_clades}\")\n",
    "    \n",
    "    # 按Clade过滤\n",
    "    for clade, expected_count in expected_clades.items():\n",
    "        clade_nodes = [n for n in nodes if n['clade'] == clade]\n",
    "        if clade_nodes:\n",
    "            # 按wdks排序\n",
    "            clade_nodes.sort(key=lambda x: x['wdks'], reverse=True)\n",
    "            filtered_nodes.extend(clade_nodes[:expected_count])\n",
    "            if len(clade_nodes) < expected_count and debug and date_str:\n",
    "                print(f\"警告:社区 {date_str}_{community_id} Clade {clade} 预期 {expected_count} 个节点，但只找到 {len(clade_nodes)} 个\")\n",
    "    \n",
    "    # 如果过滤后没有节点，使用所有节点\n",
    "    if not filtered_nodes:\n",
    "        filtered_nodes = nodes\n",
    "        if debug:\n",
    "            print(\"过滤后没有节点，使用所有有效节点\")\n",
    "            \n",
    "    return filtered_nodes\n",
    "\n",
    "\n",
    "def create_date_mapping_optimized(graphs, chains, debug=False):\n",
    "    \"\"\"优化的日期映射创建函数\"\"\"\n",
    "    date_to_graph_idx = {}\n",
    "    graph_date_ranges = []\n",
    "    \n",
    "    # 获取每个图的日期范围 (一次性计算)\n",
    "    for idx, g in enumerate(graphs):\n",
    "        if g and g.vs and 'Date' in g.vs[0].attributes():\n",
    "            # 一次性收集日期\n",
    "            graph_dates = []\n",
    "            for v in g.vs:\n",
    "                if 'Date' in v.attributes() and v['Date']:\n",
    "                    try:\n",
    "                        graph_dates.append(pd.to_datetime(str(v['Date'])))\n",
    "                    except:\n",
    "                        pass\n",
    "                        \n",
    "            min_date = min(graph_dates) if graph_dates else None\n",
    "            max_date = max(graph_dates) if graph_dates else None\n",
    "            graph_date_ranges.append((idx, min_date, max_date))\n",
    "        else:\n",
    "            graph_date_ranges.append((idx, None, None))\n",
    "    \n",
    "    # 调试输出\n",
    "    if debug:\n",
    "        print(\"\\n图索引和日期范围映射:\")\n",
    "        for idx, min_date, max_date in graph_date_ranges:\n",
    "            if min_date and max_date:\n",
    "                print(f\"  图索引[{idx}] -> 日期范围: {min_date.strftime('%Y-%m-%d')} 至 {max_date.strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    # 收集所有需要映射的日期\n",
    "    all_dates = set()\n",
    "    \n",
    "    # 从图中收集日期\n",
    "    for _, _, max_date in graph_date_ranges:\n",
    "        if max_date:\n",
    "            all_dates.add(max_date.strftime('%Y-%m-%d'))\n",
    "    \n",
    "    # 从链条中收集日期 (优化处理逻辑)\n",
    "    for chain_df in chains:\n",
    "        if not chain_df.empty:\n",
    "            # 处理日期列或日期索引\n",
    "            if isinstance(chain_df.index, pd.DatetimeIndex):\n",
    "                all_dates.update(chain_df.index.astype(str))\n",
    "            elif 'Date' in chain_df.columns:\n",
    "                all_dates.update(chain_df['Date'].astype(str))\n",
    "    \n",
    "    # 为每个日期创建映射\n",
    "    for date_str in sorted(all_dates):\n",
    "        try:\n",
    "            date = pd.to_datetime(date_str)\n",
    "            \n",
    "            # 优先精确匹配\n",
    "            exact_matches = [(idx, max_date) for idx, _, max_date in graph_date_ranges \n",
    "                           if max_date and max_date.strftime('%Y-%m-%d') == date_str]\n",
    "            \n",
    "            if exact_matches:\n",
    "                matching_idx = exact_matches[0][0]\n",
    "            else:\n",
    "                # 找最大日期小于等于该日期的最后一个图\n",
    "                lesser_or_equal_matches = [(idx, max_date) for idx, _, max_date in graph_date_ranges \n",
    "                                         if max_date and max_date <= date]\n",
    "                \n",
    "                if lesser_or_equal_matches:\n",
    "                    matching_idx = max(lesser_or_equal_matches, key=lambda x: x[1])[0]\n",
    "                else:\n",
    "                    # 找最大日期大于该日期的第一个图\n",
    "                    greater_matches = [(idx, max_date) for idx, _, max_date in graph_date_ranges \n",
    "                                     if max_date and max_date > date]\n",
    "                    \n",
    "                    if greater_matches:\n",
    "                        matching_idx = min(greater_matches, key=lambda x: x[1])[0]\n",
    "                    else:\n",
    "                        # 使用第一个有效索引\n",
    "                        valid_indices = [idx for idx, _, _ in graph_date_ranges if idx is not None]\n",
    "                        matching_idx = min(valid_indices) if valid_indices else 0\n",
    "            \n",
    "            date_to_graph_idx[date_str] = matching_idx\n",
    "        except:\n",
    "            if debug:\n",
    "                print(f\"无法处理日期: {date_str}\")\n",
    "    \n",
    "    return date_to_graph_idx\n",
    "\n",
    "def process_communities_optimized(chains, graphs, communities, date_to_graph_idx, clade_attr, debug=False):\n",
    "    \"\"\"优化的社区处理函数\"\"\"\n",
    "    node_data = {}\n",
    "    community_data = {}\n",
    "    processed_communities = set()\n",
    "    \n",
    "    # 提取counts列 (缓存处理)\n",
    "    counts_columns = []\n",
    "    if chains and len(chains) > 0 and not chains[0].empty:\n",
    "        counts_columns = [col for col in chains[0].columns if 'Counts' in col]\n",
    "    \n",
    "    # 处理社区链 (使用单次遍历优化)\n",
    "    for chain_df in chains:\n",
    "        if chain_df.empty:\n",
    "            continue\n",
    "        \n",
    "        for _, row in chain_df.iterrows():\n",
    "            # 获取日期\n",
    "            if 'Date' in row:\n",
    "                date_str = str(row['Date'])\n",
    "            else:\n",
    "                date_str = str(row.name)\n",
    "                \n",
    "            community_id = int(row['Community ID'])\n",
    "            key = (date_str, community_id)\n",
    "            \n",
    "            # 跳过已处理的社区\n",
    "            if key in processed_communities:\n",
    "                continue\n",
    "                \n",
    "            processed_communities.add(key)\n",
    "            \n",
    "            # 获取counts信息和预期的Clade分布\n",
    "            counts_info = {}\n",
    "            expected_clades = {}\n",
    "            \n",
    "            # 优化counts信息提取\n",
    "            for col in counts_columns:\n",
    "                if col in row:\n",
    "                    counts_info[col] = row[col]\n",
    "                    if ('Clade Counts' in col) or (clade_attr in col and 'Count' in col):\n",
    "                        try:\n",
    "                            clade_counts_str = str(row[col])\n",
    "                            if clade_counts_str.startswith('{') and clade_counts_str.endswith('}'):\n",
    "                                clean_str = clade_counts_str.replace(\"'\", \"\\\"\")\n",
    "                                clade_counts = json.loads(clean_str)\n",
    "                                expected_clades.update(clade_counts)\n",
    "                        except Exception as e:\n",
    "                            if debug:\n",
    "                                print(f\"解析Clade信息出错: {e}, 原始值: {row[col]}\")\n",
    "            \n",
    "            # 查找图索引\n",
    "            graph_idx = date_to_graph_idx.get(date_str)\n",
    "            if graph_idx is None or graph_idx >= len(graphs):\n",
    "                if debug:\n",
    "                    print(f\"无法找到日期 {date_str} 的图索引\")\n",
    "                continue\n",
    "                \n",
    "            graph = graphs[graph_idx]\n",
    "            if not graph:\n",
    "                continue\n",
    "            \n",
    "            # 获取社区节点\n",
    "            community_nodes = []\n",
    "            if graph_idx < len(communities) and communities[graph_idx]:\n",
    "                if 0 <= community_id < len(communities[graph_idx]):\n",
    "                    community_nodes = communities[graph_idx][community_id]\n",
    "                elif debug:\n",
    "                    print(f\"警告: 社区ID {community_id} (日期 {date_str}) 超出范围\")\n",
    "            \n",
    "            # 处理社区节点 (优化处理逻辑)\n",
    "            found_nodes = []\n",
    "            found_clades = Counter()\n",
    "            max_wdks = -1\n",
    "            \n",
    "            for node_name in community_nodes:\n",
    "                try:\n",
    "                    graph_node = graph.vs.find(name=node_name)\n",
    "                    \n",
    "                    # 获取节点信息\n",
    "                    clade = None\n",
    "                    if clade_attr in graph_node.attributes():\n",
    "                        clade = str(graph_node[clade_attr])\n",
    "                        found_clades[clade] += 1\n",
    "                    \n",
    "                    wdks_value = float(graph_node['wdks']) if 'wdks' in graph_node.attributes() else 0\n",
    "                    \n",
    "                    # 存储有效节点\n",
    "                    found_nodes.append({\n",
    "                        'name': node_name,\n",
    "                        'node': graph_node,\n",
    "                        'clade': clade,\n",
    "                        'wdks': wdks_value\n",
    "                    })\n",
    "                    \n",
    "                    # 跟踪最高wdks\n",
    "                    if wdks_value > max_wdks:\n",
    "                        max_wdks = wdks_value\n",
    "                except Exception as e:\n",
    "                    if debug:\n",
    "                        print(f\"处理节点错误: {node_name}, {e}\")\n",
    "            \n",
    "            # 过滤节点 (保留原有过滤逻辑)\n",
    "            filtered_nodes = filter_nodes_by_clade(found_nodes, expected_clades, debug, date_str, community_id)\n",
    "            \n",
    "            # 保存社区数据\n",
    "            community_data[key] = {\n",
    "                'counts': counts_info,\n",
    "                'max_wdks': max_wdks,\n",
    "                'expected_clades': expected_clades\n",
    "            }\n",
    "            \n",
    "            # 添加所有节点 (确保没有节点数量限制)\n",
    "            for node_info in filtered_nodes:\n",
    "                node_name = node_info['name']\n",
    "                graph_node = node_info['node']\n",
    "                node_id = f\"{date_str}_{community_id}_{node_name}\"\n",
    "                \n",
    "                # 基础属性\n",
    "                node_attrs = {\n",
    "                    'date': date_str,\n",
    "                    'community_id': community_id,\n",
    "                    'node_name': node_name,\n",
    "                    'is_core': False,\n",
    "                    'original_graph_idx': graph_idx,\n",
    "                    'wdks': node_info['wdks']\n",
    "                }\n",
    "                \n",
    "                # 复制节点属性\n",
    "                for attr in graph_node.attributes():\n",
    "                    if attr != 'name':\n",
    "                        node_attrs[attr] = graph_node[attr]\n",
    "                \n",
    "                # 存储节点\n",
    "                node_data[node_id] = node_attrs\n",
    "            \n",
    "            # 标记核心节点\n",
    "            if filtered_nodes:\n",
    "                max_wdks_node = max(filtered_nodes, key=lambda x: x['wdks'])\n",
    "                core_node_id = f\"{date_str}_{community_id}_{max_wdks_node['name']}\"\n",
    "                if core_node_id in node_data:  # 确保节点存在\n",
    "                    node_data[core_node_id]['is_core'] = True\n",
    "    \n",
    "    return node_data, community_data\n",
    "\n",
    "# 修复计算布局函数中使用get方法的部分\n",
    "def calculate_layout_optimized(G, node_data, community_data, \n",
    "                              horizontal_spacing, vertical_spacing,\n",
    "                              node_spread_factor, x_radius_scale, y_radius_scale,\n",
    "                              node_size_factor, fig_width, fig_height,\n",
    "                              edge_length_factor=1.0):\n",
    "    \"\"\"优化的节点布局计算函数\"\"\"\n",
    "    # 按社区分组节点\n",
    "    nodes_by_key = defaultdict(list)\n",
    "    for node_id, attrs in node_data.items():\n",
    "        key = (attrs['date'], attrs['community_id'])\n",
    "        nodes_by_key[key].append(node_id)\n",
    "    \n",
    "    # 获取排序日期列表\n",
    "    sorted_dates = sorted(set(key[0] for key in nodes_by_key.keys()))\n",
    "    \n",
    "    # 计算社区在每个日期的分布\n",
    "    communities_by_date = defaultdict(list)\n",
    "    for key in nodes_by_key.keys():\n",
    "        date, comm_id = key\n",
    "        if comm_id not in communities_by_date[date]:\n",
    "            communities_by_date[date].append(comm_id)\n",
    "    \n",
    "    # 动态调整布局比例\n",
    "    canvas_scale_factor = min(fig_width, fig_height) / 800\n",
    "    base_layout_scale = (0.5 + node_size_factor / 20) * canvas_scale_factor\n",
    "    node_size_adjustment = 0.6 + (node_size_factor / 15)\n",
    "    \n",
    "    # 日期水平位置\n",
    "    date_to_x = {date: i * horizontal_spacing for i, date in enumerate(sorted_dates)}\n",
    "    \n",
    "    # 初始化位置字典\n",
    "    pos = {}\n",
    "    community_centers = {}\n",
    "    \n",
    "    # 收集边连接信息\n",
    "    edge_connections = defaultdict(list)\n",
    "    for e in G.es:\n",
    "        if 'type' in e.attributes() and e['type'] == 'core':\n",
    "            source = G.vs[e.source]['name']\n",
    "            target = G.vs[e.target]['name']\n",
    "            if source in node_data and target in node_data:\n",
    "                src_key = (node_data[source]['date'], node_data[source]['community_id'])\n",
    "                tgt_key = (node_data[target]['date'], node_data[target]['community_id'])\n",
    "                edge_connections[src_key].append((source, target, tgt_key))\n",
    "    \n",
    "    # 为每个社区计算布局位置\n",
    "    for key, node_ids in nodes_by_key.items():\n",
    "        date, community = key\n",
    "        x_base = date_to_x[date]\n",
    "        \n",
    "        # 计算垂直位置\n",
    "        same_date_comms = communities_by_date[date]\n",
    "        comm_idx = same_date_comms.index(community)\n",
    "        total_comms = len(same_date_comms)\n",
    "        \n",
    "        # 垂直偏移\n",
    "        y_offset = (comm_idx - (total_comms - 1) / 2) * vertical_spacing\n",
    "        \n",
    "        # 找出核心节点 - 不使用get方法\n",
    "        core_node = None\n",
    "        for node_id in node_ids:\n",
    "            if 'is_core' in node_data[node_id] and node_data[node_id]['is_core']:\n",
    "                core_node = node_id\n",
    "                break\n",
    "        \n",
    "        # 计算社区大小和调整因子\n",
    "        num_nodes = len(node_ids)\n",
    "        comm_info = community_data.get(key, {})\n",
    "        max_wdks = comm_info.get('max_wdks', 0.1) if comm_info else 0.1\n",
    "        \n",
    "        # 根据节点数量和画布大小调整社区尺寸\n",
    "        size_scale = max(0.3, min(1.5, max_wdks * 3 * base_layout_scale))\n",
    "        \n",
    "        # 调整社区大小 - 根据节点数量\n",
    "        counts_info = comm_info.get('counts', {}) if comm_info else {}\n",
    "        max_count = 0\n",
    "        for val in counts_info.values():\n",
    "            try:\n",
    "                if str(val).isdigit():\n",
    "                    max_count = max(max_count, int(val))\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        size_factor = max(0.3, min(1.5, max(num_nodes, max_count) / 8 * base_layout_scale))\n",
    "        size_scale = max(size_scale, size_factor)\n",
    "        \n",
    "        # 平衡椭圆比例\n",
    "        aspect_ratio = 1.1\n",
    "        \n",
    "        # 处理多节点社区\n",
    "        if num_nodes > 1:\n",
    "            # 增强社区空间\n",
    "            base_radius = size_scale * node_size_adjustment * 1.3\n",
    "            \n",
    "            # 椭圆半径\n",
    "            x_radius = x_radius_scale * base_radius \n",
    "            y_radius = y_radius_scale * base_radius * aspect_ratio\n",
    "            \n",
    "            center_x = x_base\n",
    "            center_y = y_offset\n",
    "            \n",
    "            # 记录社区中心\n",
    "            community_centers[key] = {\n",
    "                'x': center_x,\n",
    "                'y': center_y,\n",
    "                'x_radius': x_radius * 1.1,\n",
    "                'y_radius': y_radius * 1.1,\n",
    "                'max_wdks': max_wdks,\n",
    "                'node_count': num_nodes,\n",
    "                'counts': counts_info\n",
    "            }\n",
    "            \n",
    "            # 核心节点居中\n",
    "            if core_node:\n",
    "                pos[core_node] = (center_x, center_y)\n",
    "                node_ids = [n for n in node_ids if n != core_node]  # 安全地移除核心节点\n",
    "                \n",
    "            # 根据节点数量确定布局策略\n",
    "            if node_ids:\n",
    "                if len(node_ids) <= 5:\n",
    "                    # 少量节点使用圆形布局\n",
    "                    distribute_nodes_circular(node_ids, center_x, center_y, x_radius, y_radius, \n",
    "                                            node_spread_factor * 0.9, pos)\n",
    "                else:\n",
    "                    # 多节点使用螺旋布局\n",
    "                    distribute_nodes_with_jitter(node_ids, center_x, center_y, x_radius, y_radius, \n",
    "                                               node_spread_factor, pos)\n",
    "                \n",
    "                # 迭代优化节点位置减少重叠\n",
    "                optimize_node_positions(node_ids, pos, node_size_factor, x_radius, y_radius, 5)\n",
    "        else:\n",
    "            # 单节点居中\n",
    "            pos[node_ids[0]] = (x_base, y_offset)\n",
    "            community_centers[key] = {\n",
    "                'x': x_base,\n",
    "                'y': y_offset,\n",
    "                'x_radius': x_radius_scale * 0.5 * size_scale * node_size_adjustment,\n",
    "                'y_radius': y_radius_scale * 0.5 * size_scale * node_size_adjustment,\n",
    "                'max_wdks': max_wdks,\n",
    "                'node_count': 1,\n",
    "                'counts': counts_info\n",
    "            }\n",
    "    \n",
    "    # 根据演化权重调整边长度\n",
    "    if edge_length_factor > 0.1:\n",
    "        adjust_edge_lengths(G, node_data, pos, community_centers, edge_length_factor * 0.5)\n",
    "    \n",
    "    return pos, community_centers\n",
    "\n",
    "def add_legend_optimized(fig, G, clade_attr):\n",
    "    \"\"\"添加图例 (简化版)\"\"\"\n",
    "    # 添加核心节点演化边图例\n",
    "    has_core_edges = False\n",
    "    for e in G.es:\n",
    "        if 'type' in e.attributes() and e['type'] == 'core':\n",
    "            has_core_edges = True\n",
    "            break\n",
    "    \n",
    "    if has_core_edges:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[None], y=[None],\n",
    "            mode='lines',\n",
    "            line=dict(width=1.2, color='rgba(100, 100, 180, 0.35)'),\n",
    "            name='Community Connection',\n",
    "            legendgroup='edges'\n",
    "        ))\n",
    "    \n",
    "    # 添加Clade颜色图例\n",
    "    all_clades = set()\n",
    "    for i in range(len(G.vs)):\n",
    "        if clade_attr in G.vs[i].attributes() and G.vs[i][clade_attr]:\n",
    "            all_clades.add(str(G.vs[i][clade_attr]))\n",
    "    \n",
    "    # 批量处理所有Clade\n",
    "    for i, clade in enumerate(sorted(all_clades)):\n",
    "        hue = i / max(1, len(all_clades))\n",
    "        r, g, b = colorsys.hls_to_rgb(hue, 0.5, 0.7)\n",
    "        color = f'rgb({int(r*255)}, {int(g*255)}, {int(b*255)})'\n",
    "        \n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[None], y=[None],\n",
    "            mode='markers',\n",
    "            marker=dict(size=8, color=color),\n",
    "            name=f'{clade_attr}: {clade}',\n",
    "            showlegend=True,\n",
    "            legendgroup='clades'\n",
    "        ))\n",
    "\n",
    "\n",
    "def distribute_nodes_with_jitter(node_ids, center_x, center_y, x_radius, y_radius, spread_factor, pos):\n",
    "    \"\"\"使用螺旋+扰动方法分布节点\"\"\"\n",
    "    n = len(node_ids)\n",
    "    golden_angle = np.pi * (3 - np.sqrt(5))\n",
    "    \n",
    "    # 最大半径范围\n",
    "    max_radius = 0.92\n",
    "    \n",
    "    for i, node_id in enumerate(node_ids):\n",
    "        # 基于黄金角的螺旋分布\n",
    "        radius_factor = np.sqrt(i / max(1, n-1)) * max_radius  \n",
    "        theta = i * golden_angle\n",
    "        \n",
    "        # 随机扰动\n",
    "        radius_jitter = np.random.uniform(0.85, 1.0)\n",
    "        angle_jitter = np.random.uniform(-0.2, 0.2)\n",
    "        \n",
    "        r = radius_factor * spread_factor * radius_jitter\n",
    "        final_theta = theta + angle_jitter\n",
    "        \n",
    "        x = center_x + x_radius * r * np.cos(final_theta)\n",
    "        y = center_y + y_radius * r * np.sin(final_theta)\n",
    "        \n",
    "        # 确保边界\n",
    "        rel_x = (x - center_x) / (x_radius * 0.98)\n",
    "        rel_y = (y - center_y) / (y_radius * 0.98)\n",
    "        \n",
    "        if rel_x*rel_x + rel_y*rel_y > 1:\n",
    "            scale = 0.98 / np.sqrt(rel_x*rel_x + rel_y*rel_y)\n",
    "            x = center_x + (x - center_x) * scale\n",
    "            y = center_y + (y - center_y) * scale\n",
    "            \n",
    "        pos[node_id] = (x, y)\n",
    "\n",
    "def visualize_evolution_chains(\n",
    "    final_chains: List[pd.DataFrame], \n",
    "    graphs: List[ig.Graph],\n",
    "    communities: List[List[List[str]]],\n",
    "    output_file: Optional[str] = None,\n",
    "    title: str = \"Community Evolution Network\",\n",
    "    # 布局参数\n",
    "    node_size_factor: float = 15,\n",
    "    horizontal_spacing: float = 0.75, \n",
    "    vertical_spacing: float = 1.5,\n",
    "    node_spread_factor: float = 0.9,\n",
    "    x_radius_scale: float = 0.5,\n",
    "    y_radius_scale: float = 1.2,\n",
    "    edge_length_factor: float = 1.0,\n",
    "    # 尺寸和外观参数\n",
    "    fig_width: float = 1600,          # 图表宽度，小于100为英寸\n",
    "    fig_height: float = 1000,         # 图表高度，小于100为英寸\n",
    "    dpi: int = 100,                   # 图表分辨率\n",
    "    legend_font_size: int = 20,       # 图例字体大小\n",
    "    title_font_size: int = 26,        # 标题字体大小\n",
    "    axis_font_size: int = 20,         # 坐标轴字体大小\n",
    "    font_path: str = None,\n",
    "    hover_attrs: Optional[Set[str]] = None,\n",
    "    start_date: Optional[str] = None,\n",
    "    end_date: Optional[str] = None,\n",
    "    time_interval: int = 7,\n",
    "    recording_label: str = \"Clade\",\n",
    "    date_format: str = \"%m-%d\",       # 日期格式，如\"%Y-%m-%d\"显示年份\n",
    "    # 时间轴控制\n",
    "    show_all_dates: bool = True,      # 是否显示全部日期\n",
    "    max_date_ticks: int = 5,          # 不显示全部时，显示的日期数量\n",
    "    # 位置调整\n",
    "    legend_y_pos: float = 0.01,       # 图例y轴位置 (0-1之间)\n",
    "    time_axis_y_pos: float = -0.1,    # 时间轴y轴位置偏移\n",
    "    debug: bool = False\n",
    ") -> go.Figure:\n",
    "    \"\"\"优化的社区演化链可视化函数\"\"\"\n",
    "    # 基础设置\n",
    "    font_family = load_font(font_path)\n",
    "    if hover_attrs is None:\n",
    "        hover_attrs = {'ID', 'Date', 'Community', 'wdks', 'Location'}\n",
    "    \n",
    "    # 尺寸计算\n",
    "    if fig_width < 100:\n",
    "        actual_width = int(fig_width * dpi)\n",
    "        if debug:\n",
    "            print(f\"图表宽度: {fig_width} 英寸 = {actual_width} 像素\")\n",
    "    else:\n",
    "        actual_width = int(fig_width)\n",
    "        \n",
    "    if fig_height < 100:\n",
    "        actual_height = int(fig_height * dpi)\n",
    "        if debug:\n",
    "            print(f\"图表高度: {fig_height} 英寸 = {actual_height} 像素\")\n",
    "    else:\n",
    "        actual_height = int(fig_height)\n",
    "    \n",
    "    # 确保最小尺寸\n",
    "    actual_width = max(actual_width, 300)\n",
    "    actual_height = max(actual_height, 200)\n",
    "    \n",
    "    # 数据处理\n",
    "    start_idx, end_idx, date_range = extract_date_range_optimized(graphs, start_date, end_date, time_interval)\n",
    "    if start_idx == -1 or end_idx == -1 or date_range is None:\n",
    "        return create_empty_figure(\"未找到匹配的日期范围\", actual_width, actual_height, font_family)\n",
    "    \n",
    "    # 准备数据\n",
    "    selected_graphs = graphs[start_idx:end_idx+1]\n",
    "    selected_communities = communities[start_idx:end_idx+1]\n",
    "    clade_attr = recording_label\n",
    "    lineage_attr = get_lineage_attr(selected_graphs)\n",
    "    date_to_graph_idx = create_date_mapping_optimized(selected_graphs, final_chains, debug)\n",
    "    \n",
    "    # 处理社区和节点数据\n",
    "    node_data, community_data = process_communities_optimized(\n",
    "        final_chains, selected_graphs, selected_communities, \n",
    "        date_to_graph_idx, clade_attr, debug\n",
    "    )\n",
    "    \n",
    "    if not node_data:\n",
    "        return create_empty_figure(\"无可视化数据\", actual_width, actual_height, font_family)\n",
    "    \n",
    "    # 创建图形结构并计算布局\n",
    "    G = create_graph_optimized(node_data, community_data, final_chains)\n",
    "    pos, community_centers = calculate_layout_optimized(\n",
    "        G, node_data, community_data,\n",
    "        horizontal_spacing, vertical_spacing, \n",
    "        node_spread_factor, x_radius_scale, y_radius_scale,\n",
    "        node_size_factor, actual_width, actual_height,\n",
    "        edge_length_factor\n",
    "    )\n",
    "    \n",
    "    # 创建图形\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # 添加可视化元素\n",
    "    add_community_ellipses_optimized(fig, community_centers)\n",
    "    add_edges_optimized(fig, G, pos)\n",
    "    add_nodes_optimized(fig, G, pos, node_size_factor, clade_attr, lineage_attr, hover_attrs)\n",
    "    add_legend_optimized(fig, G, clade_attr)\n",
    "    \n",
    "    # 获取和格式化所有日期\n",
    "    all_date_strings = sorted(set(node_data[n]['date'] for n in node_data))\n",
    "    all_formatted_dates = format_date_labels(all_date_strings, date_format)\n",
    "    \n",
    "    # 时间轴日期处理\n",
    "    if show_all_dates or len(all_date_strings) <= max_date_ticks:\n",
    "        # 显示全部日期\n",
    "        tick_vals = [pos[next(n for n in node_data if node_data[n]['date'] == date)][0] \n",
    "                    for date in all_date_strings]\n",
    "        tick_texts = all_formatted_dates\n",
    "    else:\n",
    "        # 均匀采样日期点\n",
    "        selected_indices = select_evenly_spaced_dates(all_date_strings, max_date_ticks)\n",
    "        selected_dates = [all_date_strings[i] for i in selected_indices]\n",
    "        selected_formatted = [all_formatted_dates[i] for i in selected_indices]\n",
    "        tick_vals = [pos[next(n for n in node_data if node_data[n]['date'] == date)][0] \n",
    "                    for date in selected_dates]\n",
    "        tick_texts = selected_formatted\n",
    "    \n",
    "    # 计算边距\n",
    "    top_margin = min(80, actual_height // 10)\n",
    "    bottom_margin = min(actual_height // 5, 80)\n",
    "    left_margin = 10\n",
    "    right_margin = 10\n",
    "    \n",
    "    # 更新布局\n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=title, \n",
    "            font=dict(family=font_family, size=title_font_size, color=\"black\"),\n",
    "            x=0.5,\n",
    "            y=0.95,\n",
    "            xanchor=\"center\",\n",
    "            yanchor=\"top\"\n",
    "        ),\n",
    "        showlegend=True,\n",
    "        hovermode='closest',\n",
    "        margin=dict(\n",
    "            l=left_margin,\n",
    "            r=right_margin,\n",
    "            t=top_margin,\n",
    "            b=bottom_margin\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            title=dict(\n",
    "                text='Time', \n",
    "                standoff=5, \n",
    "                font=dict(family=font_family, size=axis_font_size)\n",
    "            ),\n",
    "            # 使用计算好的刻度值和文本\n",
    "            tickmode='array',\n",
    "            tickvals=tick_vals,\n",
    "            ticktext=tick_texts,\n",
    "            tickangle=0,\n",
    "            tickfont=dict(family=font_family, size=axis_font_size),\n",
    "            showgrid=True,\n",
    "            # 时间轴位置调整\n",
    "            position=time_axis_y_pos\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showgrid=False, \n",
    "            zeroline=False, \n",
    "            showticklabels=False,\n",
    "        ),\n",
    "        plot_bgcolor='white',\n",
    "        font=dict(family=font_family),\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=legend_y_pos,  # 可调节图例位置\n",
    "            xanchor=\"center\",\n",
    "            x=0.5,\n",
    "            font=dict(family=font_family, size=legend_font_size),\n",
    "            itemsizing=\"constant\",\n",
    "            itemwidth=50,\n",
    "            traceorder=\"normal\",\n",
    "            tracegroupgap=8\n",
    "        ),\n",
    "        # 显式设置图表尺寸\n",
    "        width=actual_width,\n",
    "        height=actual_height,\n",
    "        autosize=False\n",
    "    )\n",
    "    \n",
    "    # 保存图表\n",
    "    if output_file:\n",
    "        save_figure_to_html(fig, output_file, dpi)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# 新增函数：均匀选择日期点\n",
    "def select_evenly_spaced_dates(dates, max_count):\n",
    "    \"\"\"均匀选择日期点的索引\n",
    "    \n",
    "    参数:\n",
    "        dates: 所有日期字符串列表\n",
    "        max_count: 最大选择数量\n",
    "        \n",
    "    返回:\n",
    "        均匀间隔的索引列表\n",
    "    \"\"\"\n",
    "    n = len(dates)\n",
    "    if n <= max_count:\n",
    "        return list(range(n))\n",
    "    \n",
    "    # 确保包含第一个和最后一个日期\n",
    "    indices = [0, n-1]\n",
    "    \n",
    "    # 如果需要更多点，均匀分布\n",
    "    if max_count > 2:\n",
    "        step = (n - 1) / (max_count - 1)\n",
    "        for i in range(1, max_count - 1):\n",
    "            idx = int(round(step * i))\n",
    "            if idx not in indices:\n",
    "                indices.append(idx)\n",
    "    \n",
    "    return sorted(indices)\n",
    "\n",
    "def format_date_labels(date_strings, date_format=\"%m-%d\"):\n",
    "    \"\"\"格式化日期标签\"\"\"\n",
    "    formatted_dates = []\n",
    "    \n",
    "    for date_str in date_strings:\n",
    "        try:\n",
    "            date = pd.to_datetime(date_str)\n",
    "            formatted_dates.append(date.strftime(date_format))\n",
    "        except:\n",
    "            # 如果无法解析日期，使用原始字符串\n",
    "            formatted_dates.append(date_str)\n",
    "    \n",
    "    return formatted_dates\n",
    "\n",
    "# 简化的辅助函数\n",
    "def load_font(font_path):\n",
    "    \"\"\"加载字体\"\"\"\n",
    "    font_family = 'Times'\n",
    "    if font_path:\n",
    "        try:\n",
    "            from matplotlib import font_manager\n",
    "            font_manager.fontManager.addfont(font_path)\n",
    "            font_family = font_manager.FontProperties(fname=font_path).get_name()\n",
    "        except Exception as e:\n",
    "            print(f\"字体加载错误: {e}，使用默认字体\")\n",
    "    return font_family\n",
    "\n",
    "def get_lineage_attr(graphs):\n",
    "    \"\"\"获取谱系属性名称\"\"\"\n",
    "    for g in graphs:\n",
    "        if g and g.vs and 'Lineage' in g.vs[0].attributes():\n",
    "            return 'Lineage'\n",
    "    return None\n",
    "\n",
    "def create_empty_figure(message, width, height, font_family='Arial'):\n",
    "    \"\"\"创建空图表\"\"\"\n",
    "    return go.Figure().update_layout(\n",
    "        title=dict(text=message, font=dict(family=font_family)),\n",
    "        annotations=[dict(text=message, x=0.5, y=0.5, showarrow=False, font=dict(family=font_family))],\n",
    "        width=width, height=height\n",
    "    )\n",
    "\n",
    "# 简化的节点分布函数\n",
    "def distribute_nodes_circular(node_ids, center_x, center_y, x_radius, y_radius, spread_factor, pos):\n",
    "    \"\"\"在圆周上均匀分布节点\"\"\"\n",
    "    angles = np.linspace(0, 2*np.pi, len(node_ids), endpoint=False)\n",
    "    np.random.shuffle(angles)\n",
    "    \n",
    "    for i, node_id in enumerate(node_ids):\n",
    "        r_factor = np.random.uniform(0.7, 0.95)\n",
    "        x = center_x + x_radius * spread_factor * r_factor * np.cos(angles[i])\n",
    "        y = center_y + y_radius * spread_factor * r_factor * np.sin(angles[i])\n",
    "        pos[node_id] = (x, y)\n",
    "\n",
    "def optimize_node_positions(node_ids, pos, node_size_factor, x_radius, y_radius, iterations=3):\n",
    "    \"\"\"优化节点位置减少重叠\"\"\"\n",
    "    if len(node_ids) <= 1:\n",
    "        return\n",
    "    \n",
    "    # 计算中心和参数\n",
    "    center_x = sum(pos[node_id][0] for node_id in node_ids) / len(node_ids)\n",
    "    center_y = sum(pos[node_id][1] for node_id in node_ids) / len(node_ids)\n",
    "    min_distance = node_size_factor / 35\n",
    "    \n",
    "    # 减少迭代次数\n",
    "    for _ in range(iterations):\n",
    "        for node1 in node_ids:\n",
    "            x1, y1 = pos[node1]\n",
    "            move_x, move_y = 0, 0\n",
    "            \n",
    "            # 计算排斥力\n",
    "            for node2 in node_ids:\n",
    "                if node1 == node2:\n",
    "                    continue\n",
    "                \n",
    "                x2, y2 = pos[node2]\n",
    "                dx, dy = x1 - x2, y1 - y2\n",
    "                dist = np.sqrt(dx*dx + dy*dy)\n",
    "                \n",
    "                if dist < min_distance and dist > 0:\n",
    "                    force = min_distance - dist\n",
    "                    move_x += (dx / dist) * force * 0.5\n",
    "                    move_y += (dy / dist) * force * 0.5\n",
    "            \n",
    "            # 应用移动\n",
    "            if move_x != 0 or move_y != 0:\n",
    "                new_x = x1 + move_x\n",
    "                new_y = y1 + move_y\n",
    "                \n",
    "                # 确保在椭圆内\n",
    "                rel_x = (new_x - center_x) / (x_radius * 0.85)\n",
    "                rel_y = (new_y - center_y) / (y_radius * 0.85)\n",
    "                \n",
    "                if rel_x*rel_x + rel_y*rel_y <= 1:\n",
    "                    pos[node1] = (new_x, new_y)\n",
    "                else:\n",
    "                    # 拉回边界\n",
    "                    scale = 0.9 / np.sqrt(rel_x*rel_x + rel_y*rel_y)\n",
    "                    pos[node1] = (\n",
    "                        center_x + (new_x - center_x) * scale,\n",
    "                        center_y + (new_y - center_y) * scale\n",
    "                    )\n",
    "\n",
    "def adjust_edge_lengths(G, node_data, pos, community_centers, edge_length_factor):\n",
    "    \"\"\"调整边长度\"\"\"\n",
    "    for e in G.es:\n",
    "        if 'type' in e.attributes() and e['type'] == 'core' and 'evo_weight' in e.attributes():\n",
    "            source = G.vs[e.source]['name']\n",
    "            target = G.vs[e.target]['name']\n",
    "            \n",
    "            if source not in pos or target not in pos:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                evo_weight = float(e['evo_weight'])\n",
    "                src_date = node_data[source]['date']\n",
    "                tgt_date = node_data[target]['date']\n",
    "                \n",
    "                if src_date != tgt_date:\n",
    "                    # 计算调整因子\n",
    "                    adjustment = 1.0 - (evo_weight * edge_length_factor)\n",
    "                    adjustment = max(0.5, min(1.05, adjustment))\n",
    "                    \n",
    "                    # 调整目标社区位置\n",
    "                    src_x = pos[source][0]\n",
    "                    tgt_comm_id = node_data[target]['community_id']\n",
    "                    tgt_comm_nodes = [n for n in pos.keys() \n",
    "                                   if n in node_data and \n",
    "                                      node_data[n]['date'] == tgt_date and \n",
    "                                      node_data[n]['community_id'] == tgt_comm_id]\n",
    "                    \n",
    "                    # 应用调整\n",
    "                    for node_id in tgt_comm_nodes:\n",
    "                        nx, ny = pos[node_id]\n",
    "                        pos[node_id] = (src_x + (nx - src_x) * adjustment, ny)\n",
    "                    \n",
    "                    # 调整社区中心\n",
    "                    key = (tgt_date, tgt_comm_id)\n",
    "                    if key in community_centers:\n",
    "                        cx = community_centers[key]['x']\n",
    "                        community_centers[key]['x'] = src_x + (cx - src_x) * adjustment\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "# 绘图函数\n",
    "\n",
    "def add_community_ellipses_optimized(fig, community_centers):\n",
    "    \"\"\"添加社区椭圆 (优化版) - 保持原始悬停信息\"\"\"\n",
    "    for (date, comm_id), center in community_centers.items():\n",
    "        # 减少点数提高效率\n",
    "        theta = np.linspace(0, 2*np.pi, 40)\n",
    "        x = center['x'] + center['x_radius'] * np.cos(theta) * 0.9\n",
    "        y = center['y'] + center['y_radius'] * np.sin(theta) * 0.9\n",
    "        \n",
    "        # 保持原始悬停信息格式\n",
    "        hover_info = [f\"Date: {date}\", f\"Community: {comm_id}\"]\n",
    "        \n",
    "        for col, val in center['counts'].items():\n",
    "            hover_info.append(f\"{col}: {val}\")\n",
    "            \n",
    "        hover_info.append(f\"Nodes: {center['node_count']}\")\n",
    "        \n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x, y=y,\n",
    "            mode='lines',\n",
    "            line=dict(color='rgba(100, 100, 100, 0.3)', width=0.8),\n",
    "            fill='none',\n",
    "            hoverinfo='text',\n",
    "            text=\"<br>\".join(hover_info),\n",
    "            showlegend=False\n",
    "        ))\n",
    "\n",
    "def add_edges_optimized(fig, G, pos):\n",
    "    \"\"\"添加边 (优化版) - 保持原始悬停信息\"\"\"\n",
    "    # 直接批量处理边\n",
    "    intra_edges = []\n",
    "    core_edges = []\n",
    "    \n",
    "    for e in G.es:\n",
    "        source = G.vs[e.source]['name']\n",
    "        target = G.vs[e.target]['name']\n",
    "        \n",
    "        if source not in pos or target not in pos:\n",
    "            continue\n",
    "            \n",
    "        if 'type' in e.attributes() and e['type'] == 'core':\n",
    "            core_edges.append((source, target, e))\n",
    "        else:\n",
    "            intra_edges.append((source, target))\n",
    "    \n",
    "    # 添加内部边 (批量处理以提高效率)\n",
    "    if intra_edges:\n",
    "        x_values = []\n",
    "        y_values = []\n",
    "        \n",
    "        for source, target in intra_edges:\n",
    "            x0, y0 = pos[source]\n",
    "            x1, y1 = pos[target]\n",
    "            x_values.extend([x0, x1, None])\n",
    "            y_values.extend([y0, y1, None])\n",
    "        \n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x_values,\n",
    "            y=y_values,\n",
    "            mode='lines',\n",
    "            line=dict(width=0.8, color='rgba(100, 100, 100, 0.5)', dash='dot'),\n",
    "            hoverinfo='none',\n",
    "            showlegend=False\n",
    "        ))\n",
    "    \n",
    "    # 添加核心边\n",
    "    for source, target, e in core_edges:\n",
    "        x0, y0 = pos[source]\n",
    "        x1, y1 = pos[target]\n",
    "        \n",
    "        # 边宽度\n",
    "        line_width = 1.0\n",
    "        \n",
    "        # 悬停文本\n",
    "        hover_text = []\n",
    "        if 'weight' in e.attributes() and e['weight'] is not None:\n",
    "            try:\n",
    "                hover_text.append(f\"Similarity: {float(e['weight']):.2f}\")\n",
    "            except (ValueError, TypeError):\n",
    "                hover_text.append(f\"Similarity: {e['weight']}\")\n",
    "                \n",
    "        if 'evo_weight' in e.attributes() and e['evo_weight'] is not None:\n",
    "            try:\n",
    "                hover_text.append(f\"Evolution Weight: {float(e['evo_weight']):.2f}\")\n",
    "            except (ValueError, TypeError):\n",
    "                hover_text.append(f\"Evolution Weight: {e['evo_weight']}\")\n",
    "        \n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[x0, x1, None],\n",
    "            y=[y0, y1, None],\n",
    "            mode='lines',\n",
    "            line=dict(width=line_width, color='rgba(100, 100, 180, 0.35)'),\n",
    "            hoverinfo='text',\n",
    "            text=\"<br>\".join(hover_text) if hover_text else None,\n",
    "            showlegend=False\n",
    "        ))\n",
    "\n",
    "def add_nodes_optimized(fig, G, pos, node_size_factor, clade_attr, lineage_attr, hover_attrs):\n",
    "    \"\"\"添加节点 (优化版) - 保持原始悬停信息格式\"\"\"\n",
    "    # 获取Clade颜色映射\n",
    "    all_clades = set()\n",
    "    for i in range(len(G.vs)):\n",
    "        if clade_attr in G.vs[i].attributes() and G.vs[i][clade_attr]:\n",
    "            all_clades.add(str(G.vs[i][clade_attr]))\n",
    "    \n",
    "    # 预计算颜色映射\n",
    "    clade_colors = {}\n",
    "    for i, clade in enumerate(sorted(all_clades)):\n",
    "        hue = i / max(1, len(all_clades))\n",
    "        r, g, b = colorsys.hls_to_rgb(hue, 0.5, 0.7)\n",
    "        clade_colors[clade] = f'rgb({int(r*255)}, {int(g*255)}, {int(b*255)})'\n",
    "    \n",
    "    default_color = 'rgb(128, 128, 128)'\n",
    "    \n",
    "    # 收集节点数据\n",
    "    node_x = []\n",
    "    node_y = []\n",
    "    node_sizes = []\n",
    "    node_colors = []\n",
    "    hover_texts = []\n",
    "    node_symbols = []\n",
    "    \n",
    "    # 批量处理所有节点\n",
    "    for v in G.vs:\n",
    "        node_id = v['name']\n",
    "        if node_id in pos:\n",
    "            x, y = pos[node_id]\n",
    "            node_x.append(x)\n",
    "            node_y.append(y)\n",
    "            \n",
    "            # 节点大小\n",
    "            size = 1.5\n",
    "            is_core = False\n",
    "            if 'is_core' in v.attributes() and v['is_core']:\n",
    "                is_core = True\n",
    "            \n",
    "            if 'wdks' in v.attributes() and v['wdks'] is not None:\n",
    "                try:\n",
    "                    wdks_value = float(v['wdks'])\n",
    "                    size = 5 + wdks_value * node_size_factor / 4\n",
    "                    size = min(size, 12)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            node_sizes.append(size)\n",
    "            node_symbols.append('triangle-up' if is_core else 'circle')\n",
    "            \n",
    "            # 节点颜色\n",
    "            node_color = default_color\n",
    "            if clade_attr and clade_attr in v.attributes() and v[clade_attr]:\n",
    "                clade_str = str(v[clade_attr])\n",
    "                if clade_str in clade_colors:\n",
    "                    node_color = clade_colors[clade_str]\n",
    "            \n",
    "            node_colors.append(node_color)\n",
    "            \n",
    "            # 准备悬停文本 - 按照第二份代码的格式\n",
    "            hover_parts = []\n",
    "            \n",
    "            # 基本信息\n",
    "            node_id_value = v['node_name']\n",
    "            if 'ID' in v.attributes():\n",
    "                node_id_value = v['ID']\n",
    "                \n",
    "            # Clade信息\n",
    "            node_clade = v[clade_attr] if clade_attr and clade_attr in v.attributes() else None\n",
    "            node_lineage = v[lineage_attr] if lineage_attr and lineage_attr in v.attributes() else None\n",
    "            \n",
    "            # 标签构建\n",
    "            core_node_label = f\"{node_id_value}\"\n",
    "            if node_clade:\n",
    "                core_node_label += f\" ({node_clade})\"\n",
    "                if node_lineage and node_lineage != node_clade:\n",
    "                    core_node_label += f\", {node_lineage}\"\n",
    "            elif node_lineage:\n",
    "                core_node_label += f\" ({node_lineage})\"\n",
    "            \n",
    "            # 核心节点特殊标记\n",
    "            hover_parts.append(f\"{'Core Node' if is_core else 'Node'}: {core_node_label}\")\n",
    "            \n",
    "            # 添加其他属性 - 使用sorted确保属性顺序一致\n",
    "            for attr_name, attr_value in sorted([\n",
    "                (attr, v[attr]) for attr in hover_attrs \n",
    "                if attr in v.attributes() and attr.lower() not in ['id', 'date', 'community', 'wdks'] \n",
    "                and attr != clade_attr and attr != lineage_attr\n",
    "            ]):\n",
    "                hover_parts.append(f\"{attr_name}: {attr_value}\")\n",
    "            \n",
    "            # 常用属性始终添加\n",
    "            if 'wdks' in v.attributes():\n",
    "                hover_parts.append(f\"WDKS: {v['wdks']:.4f}\")\n",
    "            hover_parts.append(f\"Date: {v['date']}\")\n",
    "            hover_parts.append(f\"Community: {v['community_id']}\")\n",
    "            \n",
    "            hover_texts.append(\"<br>\".join(hover_parts))\n",
    "    \n",
    "    # 批量添加节点\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=node_x, y=node_y,\n",
    "        mode='markers',\n",
    "        hoverinfo='text',\n",
    "        text=hover_texts,\n",
    "        marker=dict(\n",
    "            color=node_colors,\n",
    "            size=node_sizes,\n",
    "            symbol=node_symbols,\n",
    "            line=dict(width=0, color='rgba(0, 0, 0, 0)'),  # 无边框\n",
    "            opacity=1.0\n",
    "        ),\n",
    "        showlegend=False,\n",
    "        hoverlabel=dict(namelength=-1),\n",
    "        hoveron='points+fills',\n",
    "        hovertemplate='%{text}<extra></extra>'\n",
    "    ))\n",
    "\n",
    "# 保存函数\n",
    "def save_figure_to_html(fig, output_file, dpi=100):\n",
    "    \"\"\"将图表保存为HTML文件\"\"\"\n",
    "    if not output_file:\n",
    "        return\n",
    "    \n",
    "    fig.write_html(\n",
    "        output_file,\n",
    "        include_plotlyjs=True,\n",
    "        include_mathjax=False,\n",
    "        full_html=True,\n",
    "        config={\n",
    "            'displayModeBar': True,\n",
    "            'responsive': True,\n",
    "            'scrollZoom': True,\n",
    "            'toImageButtonOptions': {\n",
    "                'format': 'png',\n",
    "                'filename': 'evolution_network',\n",
    "                'height': fig.layout.height,\n",
    "                'width': fig.layout.width,\n",
    "                'scale': dpi / 100\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    print(f\"已将图表保存至: {output_file}，分辨率: {dpi} DPI\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图表宽度: 4.133858267716536 英寸 = 826 像素\n",
      "图表高度: 5.846456692913386 英寸 = 1169 像素\n",
      "\n",
      "图索引和日期范围映射:\n",
      "  图索引[0] -> 日期范围: 2020-06-02 至 2020-06-08\n",
      "  图索引[1] -> 日期范围: 2020-06-01 至 2020-06-15\n",
      "  图索引[2] -> 日期范围: 2020-06-01 至 2020-06-22\n",
      "  图索引[3] -> 日期范围: 2020-06-01 至 2020-06-29\n",
      "  图索引[4] -> 日期范围: 2020-06-01 至 2020-07-06\n",
      "  图索引[5] -> 日期范围: 2020-06-01 至 2020-07-13\n",
      "  图索引[6] -> 日期范围: 2020-06-01 至 2020-07-20\n",
      "  图索引[7] -> 日期范围: 2020-06-01 至 2020-07-27\n",
      "  图索引[8] -> 日期范围: 2020-06-01 至 2020-08-03\n",
      "  图索引[9] -> 日期范围: 2020-06-01 至 2020-08-10\n",
      "  图索引[10] -> 日期范围: 2020-06-01 至 2020-08-17\n",
      "  图索引[11] -> 日期范围: 2020-06-01 至 2020-08-24\n",
      "  图索引[12] -> 日期范围: 2020-06-01 至 2020-08-31\n",
      "  图索引[13] -> 日期范围: 2020-06-01 至 2020-09-07\n",
      "  图索引[14] -> 日期范围: 2020-06-01 至 2020-09-14\n",
      "  图索引[15] -> 日期范围: 2020-06-01 至 2020-09-21\n",
      "  图索引[16] -> 日期范围: 2020-06-01 至 2020-09-28\n",
      "  图索引[17] -> 日期范围: 2020-06-01 至 2020-10-05\n",
      "  图索引[18] -> 日期范围: 2020-06-01 至 2020-10-12\n",
      "  图索引[19] -> 日期范围: 2020-06-01 至 2020-10-19\n",
      "  图索引[20] -> 日期范围: 2020-06-01 至 2020-10-26\n",
      "  图索引[21] -> 日期范围: 2020-06-01 至 2020-11-02\n",
      "已将图表保存至: evolution_visualization_P_2.html，分辨率: 200 DPI\n"
     ]
    }
   ],
   "source": [
    "fig = visualize_evolution_chains(\n",
    "    final_chains=tracking_chains_eu, start_date='2020-06-08',\n",
    "    end_date='2020-11-02', time_interval=7, graphs=graphs2, recording_label='Lineage',\n",
    "    communities=communities2,font_path='/home/liujiajun/projects/Hap_networks/TIMES.TTF',      \n",
    "    output_file=None,dpi=200,\n",
    "    fig_width=0.5*210 / 25.4, fig_height=0.5*297 / 25.4, debug=True,\n",
    "    node_size_factor=30,           # 适当减小节点大小\n",
    "    vertical_spacing=1.8,          # 增加垂直间距\n",
    "    horizontal_spacing=1.2,        # 增加水平间距\n",
    "    node_spread_factor=1.5,        # 减小节点分散系数，确保在椭圆内\n",
    "    x_radius_scale=0.1*0.8,           # 更均衡的椭圆比例\n",
    "    y_radius_scale=0.15*0.8,           # 更均衡的椭圆比例\n",
    "    edge_length_factor=0.2,        # 弱化边长度与权重的关联\n",
    "        title='The evolution path of the SARS-CoV-2 P.2 lineage',     show_all_dates=False,  # 不显示所有时间点\n",
    "    max_date_ticks=5,    legend_y_pos = -0.17, \n",
    "    time_axis_y_pos= 0, \n",
    ")\n",
    "\n",
    "# 使用专门的保存函数\n",
    "save_figure_to_html(fig, \"evolution_visualization_P_2.html\",dpi=200)\n",
    "# 显示或保存图表\n",
    "#fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ljj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
